{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8537196,"sourceType":"datasetVersion","datasetId":5099533}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport numpy as np\nimport spacy\nimport torchtext\nimport tqdm\nimport random\nfrom spacy.lang.vi import Vietnamese\nfrom spacy.lang.en import English\nfrom torch.utils.data import Dataset, random_split\nfrom torchtext.vocab import build_vocab_from_iterator","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:11.081210Z","iopub.execute_input":"2024-05-28T06:47:11.081812Z","iopub.status.idle":"2024-05-28T06:47:19.710000Z","shell.execute_reply.started":"2024-05-28T06:47:11.081775Z","shell.execute_reply":"2024-05-28T06:47:19.709186Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"seed = 1234\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.711829Z","iopub.execute_input":"2024-05-28T06:47:19.712414Z","iopub.status.idle":"2024-05-28T06:47:19.720108Z","shell.execute_reply.started":"2024-05-28T06:47:19.712387Z","shell.execute_reply":"2024-05-28T06:47:19.719190Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def load_data(path):\n    data = []\n    with open(path,'r') as file:\n        for line in file.readlines():\n            splitted_line = line.split('\\t')\n            eng = splitted_line[0]\n            vi = splitted_line[1]\n            data.append({'vi':vi, \n                         'en':eng})\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.721472Z","iopub.execute_input":"2024-05-28T06:47:19.722120Z","iopub.status.idle":"2024-05-28T06:47:19.729554Z","shell.execute_reply.started":"2024-05-28T06:47:19.722085Z","shell.execute_reply":"2024-05-28T06:47:19.728627Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, index):\n        return self.data[index]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.730642Z","iopub.execute_input":"2024-05-28T06:47:19.730950Z","iopub.status.idle":"2024-05-28T06:47:19.740323Z","shell.execute_reply.started":"2024-05-28T06:47:19.730928Z","shell.execute_reply":"2024-05-28T06:47:19.739539Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataset = CustomDataset(load_data('/kaggle/input/languagedata/data/vie.txt'))","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.743130Z","iopub.execute_input":"2024-05-28T06:47:19.743411Z","iopub.status.idle":"2024-05-28T06:47:19.937659Z","shell.execute_reply.started":"2024-05-28T06:47:19.743388Z","shell.execute_reply":"2024-05-28T06:47:19.936859Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#7:2:1\ntotal_samples = len(dataset)\ntrain_size = int(0.8 * total_samples)\nval_size = int(0.1 * total_samples)\ntest_size = total_samples - train_size - val_size","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.938857Z","iopub.execute_input":"2024-05-28T06:47:19.939156Z","iopub.status.idle":"2024-05-28T06:47:19.944226Z","shell.execute_reply.started":"2024-05-28T06:47:19.939131Z","shell.execute_reply":"2024-05-28T06:47:19.943353Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data, test_data = random_split(dataset, [train_size, val_size, test_size])\nprint(\"Số lượng mẫu trong tập train:\", len(train_data))\nprint(\"Số lượng mẫu trong tập validation:\", len(valid_data))\nprint(\"Số lượng mẫu trong tập test:\", len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.945610Z","iopub.execute_input":"2024-05-28T06:47:19.946447Z","iopub.status.idle":"2024-05-28T06:47:19.969812Z","shell.execute_reply.started":"2024-05-28T06:47:19.946419Z","shell.execute_reply":"2024-05-28T06:47:19.968838Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Số lượng mẫu trong tập train: 7542\nSố lượng mẫu trong tập validation: 942\nSố lượng mẫu trong tập test: 944\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.971125Z","iopub.execute_input":"2024-05-28T06:47:19.971505Z","iopub.status.idle":"2024-05-28T06:47:19.979310Z","shell.execute_reply.started":"2024-05-28T06:47:19.971473Z","shell.execute_reply":"2024-05-28T06:47:19.978153Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?'}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenizer","metadata":{}},{"cell_type":"code","source":"!pip install pyvi","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:19.980634Z","iopub.execute_input":"2024-05-28T06:47:19.980923Z","iopub.status.idle":"2024-05-28T06:47:34.333969Z","shell.execute_reply.started":"2024-05-28T06:47:19.980896Z","shell.execute_reply":"2024-05-28T06:47:34.332737Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting pyvi\n  Downloading pyvi-0.1.1-py2.py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pyvi) (1.2.2)\nCollecting sklearn-crfsuite (from pyvi)\n  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pyvi) (3.2.0)\nCollecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\nRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.10/site-packages (from sklearn-crfsuite->pyvi) (4.66.1)\nDownloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\nDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n","output_type":"stream"}]},{"cell_type":"code","source":"en_nlp = English()\nvi_nlp = Vietnamese()","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:34.335942Z","iopub.execute_input":"2024-05-28T06:47:34.336325Z","iopub.status.idle":"2024-05-28T06:47:35.054230Z","shell.execute_reply.started":"2024-05-28T06:47:34.336290Z","shell.execute_reply":"2024-05-28T06:47:35.053106Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"string = \"What a lovely day it is today!\"\n[token.text for token in en_nlp.tokenizer(string)]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:35.055976Z","iopub.execute_input":"2024-05-28T06:47:35.056296Z","iopub.status.idle":"2024-05-28T06:47:35.063319Z","shell.execute_reply.started":"2024-05-28T06:47:35.056268Z","shell.execute_reply":"2024-05-28T06:47:35.062284Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_example(example, en_nlp, vi_nlp, max_length, lower, sos_token, eos_token):\n    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n    vi_tokens = [token.text for token in vi_nlp.tokenizer(example[\"vi\"])][:max_length]\n    if lower:\n        en_tokens = [token.lower() for token in en_tokens]\n        vi_tokens = [token.lower() for token in vi_tokens]\n    en_tokens = [sos_token] + en_tokens + [eos_token]\n    vi_tokens = [sos_token] + vi_tokens + [eos_token]\n    example[\"en_tokens\"] = en_tokens\n    example[\"vi_tokens\"] = vi_tokens\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:35.064855Z","iopub.execute_input":"2024-05-28T06:47:35.065248Z","iopub.status.idle":"2024-05-28T06:47:35.076103Z","shell.execute_reply.started":"2024-05-28T06:47:35.065214Z","shell.execute_reply":"2024-05-28T06:47:35.075152Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"max_length = 1_000\nlower = True\nsos_token = \"<sos>\"\neos_token = \"<eos>\"\n\nfn_kwargs = {\n    \"en_nlp\": en_nlp,\n    \"vi_nlp\": vi_nlp,\n    \"max_length\": max_length,\n    \"lower\": lower,\n    \"sos_token\": sos_token,\n    \"eos_token\": eos_token,\n}\ntrain_data = [tokenize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [tokenize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [tokenize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:35.077270Z","iopub.execute_input":"2024-05-28T06:47:35.077541Z","iopub.status.idle":"2024-05-28T06:47:38.380291Z","shell.execute_reply.started":"2024-05-28T06:47:35.077518Z","shell.execute_reply":"2024-05-28T06:47:38.379409Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.385860Z","iopub.execute_input":"2024-05-28T06:47:38.386173Z","iopub.status.idle":"2024-05-28T06:47:38.393003Z","shell.execute_reply.started":"2024-05-28T06:47:38.386150Z","shell.execute_reply":"2024-05-28T06:47:38.392011Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"def yield_tokens(data,s):\n    for dct in data:\n        yield dct[s]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.394199Z","iopub.execute_input":"2024-05-28T06:47:38.394513Z","iopub.status.idle":"2024-05-28T06:47:38.403409Z","shell.execute_reply.started":"2024-05-28T06:47:38.394490Z","shell.execute_reply":"2024-05-28T06:47:38.402578Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"min_freq = 2\nunk_token = \"<unk>\"\npad_token = \"<pad>\"\n\nspecial_tokens = [\n    unk_token,\n    pad_token,\n    sos_token,\n    eos_token,\n]\n\nen_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'en_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)\n\nvi_vocab = torchtext.vocab.build_vocab_from_iterator(\n    yield_tokens(train_data,'vi_tokens'),\n    min_freq=min_freq,\n    specials=special_tokens,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.404615Z","iopub.execute_input":"2024-05-28T06:47:38.405051Z","iopub.status.idle":"2024-05-28T06:47:38.626231Z","shell.execute_reply.started":"2024-05-28T06:47:38.405020Z","shell.execute_reply":"2024-05-28T06:47:38.625446Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"en_vocab.get_itos()[:10]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.627312Z","iopub.execute_input":"2024-05-28T06:47:38.627600Z","iopub.status.idle":"2024-05-28T06:47:38.635354Z","shell.execute_reply.started":"2024-05-28T06:47:38.627566Z","shell.execute_reply":"2024-05-28T06:47:38.634569Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"['<unk>', '<pad>', '<sos>', '<eos>', '.', 'i', 'to', 'tom', 'you', 'the']"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.get_stoi()[\"the\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.636788Z","iopub.execute_input":"2024-05-28T06:47:38.637563Z","iopub.status.idle":"2024-05-28T06:47:38.647352Z","shell.execute_reply.started":"2024-05-28T06:47:38.637524Z","shell.execute_reply":"2024-05-28T06:47:38.646526Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"9"},"metadata":{}}]},{"cell_type":"code","source":"assert en_vocab[unk_token] == vi_vocab[unk_token]\nassert en_vocab[pad_token] == vi_vocab[pad_token]\n\nunk_index = en_vocab[unk_token]\npad_index = en_vocab[pad_token]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.648669Z","iopub.execute_input":"2024-05-28T06:47:38.648991Z","iopub.status.idle":"2024-05-28T06:47:38.656441Z","shell.execute_reply.started":"2024-05-28T06:47:38.648967Z","shell.execute_reply":"2024-05-28T06:47:38.655662Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"en_vocab.set_default_index(unk_index)\nvi_vocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.657555Z","iopub.execute_input":"2024-05-28T06:47:38.657852Z","iopub.status.idle":"2024-05-28T06:47:38.666924Z","shell.execute_reply.started":"2024-05-28T06:47:38.657829Z","shell.execute_reply":"2024-05-28T06:47:38.666077Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\nen_vocab.lookup_indices(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.668056Z","iopub.execute_input":"2024-05-28T06:47:38.668372Z","iopub.status.idle":"2024-05-28T06:47:38.678646Z","shell.execute_reply.started":"2024-05-28T06:47:38.668347Z","shell.execute_reply":"2024-05-28T06:47:38.677720Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[5, 173, 509, 0, 0]"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.679981Z","iopub.execute_input":"2024-05-28T06:47:38.680345Z","iopub.status.idle":"2024-05-28T06:47:38.689728Z","shell.execute_reply.started":"2024-05-28T06:47:38.680315Z","shell.execute_reply":"2024-05-28T06:47:38.688777Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['i', 'love', 'watching', '<unk>', '<unk>']"},"metadata":{}}]},{"cell_type":"code","source":"def numericalize_example(example, en_vocab, vi_vocab):\n    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n    vi_ids = vi_vocab.lookup_indices(example[\"vi_tokens\"])\n    example[\"en_ids\"] = en_ids\n    example[\"vi_ids\"] = vi_ids\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.691074Z","iopub.execute_input":"2024-05-28T06:47:38.691447Z","iopub.status.idle":"2024-05-28T06:47:38.703072Z","shell.execute_reply.started":"2024-05-28T06:47:38.691416Z","shell.execute_reply":"2024-05-28T06:47:38.702039Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"fn_kwargs = {\"en_vocab\": en_vocab, \"vi_vocab\": vi_vocab}\ntrain_data = [numericalize_example(example, **fn_kwargs) for example in train_data]\nvalid_data = [numericalize_example(example, **fn_kwargs) for example in valid_data]\ntest_data = [numericalize_example(example, **fn_kwargs) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:38.704630Z","iopub.execute_input":"2024-05-28T06:47:38.705519Z","iopub.status.idle":"2024-05-28T06:47:39.023171Z","shell.execute_reply.started":"2024-05-28T06:47:38.705463Z","shell.execute_reply":"2024-05-28T06:47:39.022280Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.024333Z","iopub.execute_input":"2024-05-28T06:47:39.024692Z","iopub.status.idle":"2024-05-28T06:47:39.032823Z","shell.execute_reply.started":"2024-05-28T06:47:39.024662Z","shell.execute_reply":"2024-05-28T06:47:39.031739Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'vi': 'Bạn thực sự muốn mặc cái đó sao?',\n 'en': 'Do you really want to wear that?',\n 'en_tokens': ['<sos>',\n  'do',\n  'you',\n  'really',\n  'want',\n  'to',\n  'wear',\n  'that',\n  '?',\n  '<eos>'],\n 'vi_tokens': ['<sos>',\n  'bạn',\n  'thực sự',\n  'muốn',\n  'mặc',\n  'cái',\n  'đó',\n  'sao',\n  '?',\n  '<eos>'],\n 'en_ids': [2, 14, 8, 88, 37, 6, 431, 15, 10, 3],\n 'vi_ids': [2, 8, 184, 30, 281, 34, 15, 97, 11, 3]}"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.lookup_tokens(train_data[0][\"en_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.034035Z","iopub.execute_input":"2024-05-28T06:47:39.034372Z","iopub.status.idle":"2024-05-28T06:47:39.046497Z","shell.execute_reply.started":"2024-05-28T06:47:39.034347Z","shell.execute_reply":"2024-05-28T06:47:39.045522Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['<sos>', 'do', 'you', 'really', 'want', 'to', 'wear', 'that', '?', '<eos>']"},"metadata":{}}]},{"cell_type":"code","source":"def to_tensor(example):\n    example['en_ids'] = torch.tensor(np.array(example['en_ids']), dtype=torch.int64)\n    example['vi_ids'] = torch.tensor(np.array(example['vi_ids']), dtype=torch.int64)\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.047727Z","iopub.execute_input":"2024-05-28T06:47:39.048018Z","iopub.status.idle":"2024-05-28T06:47:39.055839Z","shell.execute_reply.started":"2024-05-28T06:47:39.047994Z","shell.execute_reply":"2024-05-28T06:47:39.055031Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_data = [to_tensor(example) for example in train_data]\nvalid_data = [to_tensor(example) for example in valid_data]\ntest_data = [to_tensor(example) for example in test_data]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.056871Z","iopub.execute_input":"2024-05-28T06:47:39.057230Z","iopub.status.idle":"2024-05-28T06:47:39.285228Z","shell.execute_reply.started":"2024-05-28T06:47:39.057208Z","shell.execute_reply":"2024-05-28T06:47:39.284223Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"type(train_data[0][\"en_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.286390Z","iopub.execute_input":"2024-05-28T06:47:39.286721Z","iopub.status.idle":"2024-05-28T06:47:39.293080Z","shell.execute_reply.started":"2024-05-28T06:47:39.286695Z","shell.execute_reply":"2024-05-28T06:47:39.292008Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"code","source":"def get_collate_fn(pad_index):\n    def collate_fn(batch):\n        batch_en_ids = [example[\"en_ids\"] for example in batch]\n        batch_vi_ids = [example[\"vi_ids\"] for example in batch]\n        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n        batch_vi_ids = nn.utils.rnn.pad_sequence(batch_vi_ids, padding_value=pad_index)\n        batch = {\n            \"en_ids\": batch_en_ids.T,\n            \"vi_ids\": batch_vi_ids.T,\n        }\n        return batch\n\n    return collate_fn","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.294450Z","iopub.execute_input":"2024-05-28T06:47:39.294818Z","iopub.status.idle":"2024-05-28T06:47:39.302500Z","shell.execute_reply.started":"2024-05-28T06:47:39.294785Z","shell.execute_reply":"2024-05-28T06:47:39.301613Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n    collate_fn = get_collate_fn(pad_index)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        shuffle=shuffle,\n    )\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.303703Z","iopub.execute_input":"2024-05-28T06:47:39.304024Z","iopub.status.idle":"2024-05-28T06:47:39.314585Z","shell.execute_reply.started":"2024-05-28T06:47:39.304001Z","shell.execute_reply":"2024-05-28T06:47:39.313462Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"a = get_data_loader(train_data, 128, pad_index, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.316407Z","iopub.execute_input":"2024-05-28T06:47:39.317239Z","iopub.status.idle":"2024-05-28T06:47:39.325576Z","shell.execute_reply.started":"2024-05-28T06:47:39.317196Z","shell.execute_reply":"2024-05-28T06:47:39.324650Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\ntrain_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\nvalid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\ntest_data_loader = get_data_loader(test_data, batch_size, pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.326694Z","iopub.execute_input":"2024-05-28T06:47:39.326997Z","iopub.status.idle":"2024-05-28T06:47:39.336416Z","shell.execute_reply.started":"2024-05-28T06:47:39.326973Z","shell.execute_reply":"2024-05-28T06:47:39.335638Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.embedding = nn.Embedding(input_dim, embedding_dim,)\n        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, src):\n        #src: n x seq_length\n        embedded = self.dropout(self.embedding(src))\n        #embedded: n x seq_length x embedding_dim\n        outputs, (hidden, cell) = self.rnn(embedded)\n        #outputs: n x seq_length x hidden_dim\n        #hidden: n x num_layers x hidden_dim\n        #cell: n x num_layers x hidden_dim\n        return hidden, cell","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.337760Z","iopub.execute_input":"2024-05-28T06:47:39.338053Z","iopub.status.idle":"2024-05-28T06:47:39.350634Z","shell.execute_reply.started":"2024-05-28T06:47:39.338029Z","shell.execute_reply":"2024-05-28T06:47:39.349807Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n        super().__init__()\n        self.output_dim = output_dim\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.embedding = nn.Embedding(output_dim, embedding_dim)\n        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n        self.fc_out = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, input, hidden, cell):\n        #input: n\n        #hidden = n x num_layers x hidden_dim\n        #cell = n x num_layers x hidden_dim\n        input = input.unsqueeze(1)\n        #input: n x 1\n        embedded = self.dropout(self.embedding(input))\n        #embedded: n x 1 x embedding_dim\n        output, (hidden, cell) = self.rnn(embedded, (hidden,cell))\n        #output: n x 1 x hidden_dim\n        #hidden: n x num_layers x hidden_dim\n        #cell: n x num_layers x hidden_dim\n        prediction = self.fc_out(output.squeeze(1)) #output.squeeze(1) -> n x hidden_dim\n        #prediction: n x output_dim\n        return prediction, hidden, cell","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.351813Z","iopub.execute_input":"2024-05-28T06:47:39.352105Z","iopub.status.idle":"2024-05-28T06:47:39.362009Z","shell.execute_reply.started":"2024-05-28T06:47:39.352082Z","shell.execute_reply":"2024-05-28T06:47:39.361139Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        assert(\n            encoder.hidden_dim == decoder.hidden_dim\n        ), \"Hidden dimensions of encoder and decoder must be equal\"\n        assert(\n            encoder.n_layers == decoder.n_layers\n        ), \"Encoder and decoder must have equal number of layers\"\n    \n    def forward(self, src, trg, teacher_forcing_ratio):\n        #src: n x seq_length\n        #trg: n x seq_length\n        #teacher_forcing_ratio is probability to use teacher forcing\n        batch_size = src.shape[0]\n        trg_length = trg.shape[1]\n        trg_vocab_size = self.decoder.output_dim\n        outputs = torch.zeros(batch_size, trg_length, trg_vocab_size).to(self.device)\n        #outputs: n x trg_seq_length x output_dim\n        hidden, cell = self.encoder(src)\n        #hidden: n x num_layers x hidden_dim\n        #cell: n x num_layers x hidden_dim\n        #first input to the decoder is the <sos> token\n        input = trg[:,0]\n        #input: n\n        for t in range(1, trg_length):\n            output, hidden, cell = self.decoder(input, hidden, cell)\n            #output: n x output_dim\n            #hidden: n x num_layers x hidden_dim\n            #cell: n x num_layers x hidden_dim\n            outputs[:,t,:] = output\n            teacher_force = random.random() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            input = trg[:,t] if teacher_force else top1\n            #input: n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.363057Z","iopub.execute_input":"2024-05-28T06:47:39.363339Z","iopub.status.idle":"2024-05-28T06:47:39.377140Z","shell.execute_reply.started":"2024-05-28T06:47:39.363317Z","shell.execute_reply":"2024-05-28T06:47:39.376231Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"input_dim = len(en_vocab)\noutput_dim = len(vi_vocab)\nencoder_embedding_dim = 256\ndecoder_embedding_dim = 256\nhidden_dim = 512\nn_layers = 2\nencoder_dropout = 0.5\ndecoder_dropout = 0.5\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nencoder = Encoder(\n    input_dim,\n    encoder_embedding_dim,\n    hidden_dim,\n    n_layers,\n    encoder_dropout,\n)\n\ndecoder = Decoder(\n    output_dim,\n    decoder_embedding_dim,\n    hidden_dim,\n    n_layers,\n    decoder_dropout,\n)\n\nmodel = Seq2Seq(encoder, decoder, device).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.378398Z","iopub.execute_input":"2024-05-28T06:47:39.378747Z","iopub.status.idle":"2024-05-28T06:47:39.755652Z","shell.execute_reply.started":"2024-05-28T06:47:39.378719Z","shell.execute_reply":"2024-05-28T06:47:39.754802Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    for name, param in m.named_parameters():\n        nn.init.uniform_(param.data, -0.08, 0.08)\nmodel.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.756981Z","iopub.execute_input":"2024-05-28T06:47:39.757351Z","iopub.status.idle":"2024-05-28T06:47:39.774300Z","shell.execute_reply.started":"2024-05-28T06:47:39.757316Z","shell.execute_reply":"2024-05-28T06:47:39.773371Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(2187, 256)\n    (rnn): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.5)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(2065, 256)\n    (rnn): LSTM(256, 512, num_layers=2, batch_first=True, dropout=0.5)\n    (fc_out): Linear(in_features=512, out_features=2065, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"The model has {count_parameters(model):,} trainable parameters\")","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.775530Z","iopub.execute_input":"2024-05-28T06:47:39.775871Z","iopub.status.idle":"2024-05-28T06:47:39.781550Z","shell.execute_reply.started":"2024-05-28T06:47:39.775846Z","shell.execute_reply":"2024-05-28T06:47:39.780649Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"The model has 9,504,273 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:39.782860Z","iopub.execute_input":"2024-05-28T06:47:39.783789Z","iopub.status.idle":"2024-05-28T06:47:41.596884Z","shell.execute_reply.started":"2024-05-28T06:47:39.783749Z","shell.execute_reply":"2024-05-28T06:47:41.595962Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def train_fn(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(data_loader):\n        src = batch['en_ids'].to(device)\n        trg = batch['vi_ids'].to(device)\n        #src: n x src_seq_length\n        #trg: n x trg_seq_length\n        optimizer.zero_grad()\n        output = model(src, trg, teacher_forcing_ratio)\n        #output: n x trg_seq_length x trg_vocab_size\n        output_dim = output.shape[-1]\n        output = output[:,1:,].reshape(-1,output_dim)\n        #output: (n * trg_seq_length - 1) x trg_vocab_size\n        trg = trg[:,1:].reshape(-1)\n        #trg: n x trg_seq_length-1\n        loss = criterion(output, trg)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:41.602912Z","iopub.execute_input":"2024-05-28T06:47:41.603454Z","iopub.status.idle":"2024-05-28T06:47:41.611292Z","shell.execute_reply.started":"2024-05-28T06:47:41.603426Z","shell.execute_reply":"2024-05-28T06:47:41.610333Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(data_loader):\n            src = batch['en_ids'].to(device)\n            trg = batch['vi_ids'].to(device)\n            #src: n x src_seq_length\n            #trg: n x trg_seq_length\n            output = model(src, trg, 0)\n            output_dim = output.shape[-1]\n            output = output[:,1:,].reshape(-1,output_dim)\n            #output: n x trg_seq_legth - 1 x trg_vocab_size\n            trg = trg[:,1:].reshape(-1)\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:41.612585Z","iopub.execute_input":"2024-05-28T06:47:41.612925Z","iopub.status.idle":"2024-05-28T06:47:41.624498Z","shell.execute_reply.started":"2024-05-28T06:47:41.612899Z","shell.execute_reply":"2024-05-28T06:47:41.623642Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"\nn_epochs = 50\nclip = 2.0\nteacher_forcing_ratio = 0.5\n\nbest_valid_loss = float(\"inf\")\n\nfor epoch in tqdm.tqdm(range(n_epochs)):\n    train_loss = train_fn(\n        model,\n        train_data_loader,\n        optimizer,\n        criterion,\n        clip,\n        teacher_forcing_ratio,\n        device,\n    )\n    valid_loss = evaluate_fn(\n        model,\n        valid_data_loader,\n        criterion,\n        device,\n    )\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), \"tut1-model.pt\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:47:41.625749Z","iopub.execute_input":"2024-05-28T06:47:41.626046Z","iopub.status.idle":"2024-05-28T06:50:58.384911Z","shell.execute_reply.started":"2024-05-28T06:47:41.626014Z","shell.execute_reply":"2024-05-28T06:50:58.383847Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"  2%|▏         | 1/50 [00:04<04:00,  4.91s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   5.289 | Train PPL: 198.229\n\tValid Loss:   4.955 | Valid PPL: 141.899\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 2/50 [00:08<03:29,  4.37s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.949 | Train PPL: 140.983\n\tValid Loss:   4.942 | Valid PPL: 140.097\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 3/50 [00:12<03:15,  4.17s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.862 | Train PPL: 129.346\n\tValid Loss:   4.978 | Valid PPL: 145.127\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 4/50 [00:16<03:06,  4.05s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.803 | Train PPL: 121.861\n\tValid Loss:   4.973 | Valid PPL: 144.403\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 5/50 [00:20<03:00,  4.02s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.728 | Train PPL: 113.040\n\tValid Loss:   4.872 | Valid PPL: 130.552\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 6/50 [00:24<02:56,  4.01s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.604 | Train PPL:  99.932\n\tValid Loss:   4.798 | Valid PPL: 121.275\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 7/50 [00:28<02:51,  3.98s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.495 | Train PPL:  89.566\n\tValid Loss:   4.740 | Valid PPL: 114.425\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 8/50 [00:32<02:46,  3.98s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.360 | Train PPL:  78.253\n\tValid Loss:   4.680 | Valid PPL: 107.813\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 9/50 [00:36<02:42,  3.96s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.271 | Train PPL:  71.574\n\tValid Loss:   4.680 | Valid PPL: 107.802\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 10/50 [00:40<02:37,  3.95s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.202 | Train PPL:  66.851\n\tValid Loss:   4.689 | Valid PPL: 108.744\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 11/50 [00:44<02:33,  3.95s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.106 | Train PPL:  60.728\n\tValid Loss:   4.654 | Valid PPL: 104.983\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 12/50 [00:48<02:30,  3.95s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   4.034 | Train PPL:  56.501\n\tValid Loss:   4.589 | Valid PPL:  98.402\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 13/50 [00:52<02:26,  3.96s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.922 | Train PPL:  50.524\n\tValid Loss:   4.580 | Valid PPL:  97.562\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 14/50 [00:56<02:22,  3.95s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.844 | Train PPL:  46.721\n\tValid Loss:   4.519 | Valid PPL:  91.786\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 15/50 [01:00<02:18,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.695 | Train PPL:  40.257\n\tValid Loss:   4.470 | Valid PPL:  87.392\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 16/50 [01:04<02:14,  3.95s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.649 | Train PPL:  38.438\n\tValid Loss:   4.436 | Valid PPL:  84.408\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 17/50 [01:08<02:10,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.513 | Train PPL:  33.538\n\tValid Loss:   4.399 | Valid PPL:  81.370\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 18/50 [01:11<02:06,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.451 | Train PPL:  31.518\n\tValid Loss:   4.368 | Valid PPL:  78.857\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 19/50 [01:15<02:02,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.316 | Train PPL:  27.560\n\tValid Loss:   4.324 | Valid PPL:  75.454\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 20/50 [01:19<01:58,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.224 | Train PPL:  25.127\n\tValid Loss:   4.320 | Valid PPL:  75.177\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 21/50 [01:23<01:54,  3.96s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.091 | Train PPL:  22.000\n\tValid Loss:   4.286 | Valid PPL:  72.659\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 22/50 [01:27<01:51,  3.99s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.052 | Train PPL:  21.162\n\tValid Loss:   4.220 | Valid PPL:  68.067\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 23/50 [01:31<01:46,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.924 | Train PPL:  18.619\n\tValid Loss:   4.234 | Valid PPL:  68.968\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 24/50 [01:35<01:42,  3.93s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.829 | Train PPL:  16.924\n\tValid Loss:   4.182 | Valid PPL:  65.484\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 25/50 [01:39<01:38,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.784 | Train PPL:  16.177\n\tValid Loss:   4.164 | Valid PPL:  64.350\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 26/50 [01:43<01:34,  3.93s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.652 | Train PPL:  14.184\n\tValid Loss:   4.159 | Valid PPL:  63.999\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 27/50 [01:47<01:30,  3.92s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.578 | Train PPL:  13.173\n\tValid Loss:   4.119 | Valid PPL:  61.475\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 28/50 [01:51<01:26,  3.94s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.473 | Train PPL:  11.856\n\tValid Loss:   4.117 | Valid PPL:  61.345\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 29/50 [01:55<01:22,  3.93s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.390 | Train PPL:  10.914\n\tValid Loss:   4.100 | Valid PPL:  60.348\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 30/50 [01:59<01:18,  3.93s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.348 | Train PPL:  10.468\n\tValid Loss:   4.040 | Valid PPL:  56.849\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 31/50 [02:03<01:14,  3.92s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.250 | Train PPL:   9.491\n\tValid Loss:   4.059 | Valid PPL:  57.945\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 32/50 [02:07<01:10,  3.92s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.130 | Train PPL:   8.413\n\tValid Loss:   4.060 | Valid PPL:  57.965\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 33/50 [02:10<01:06,  3.92s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   2.076 | Train PPL:   7.976\n\tValid Loss:   4.005 | Valid PPL:  54.881\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 34/50 [02:14<01:02,  3.90s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.937 | Train PPL:   6.937\n\tValid Loss:   4.016 | Valid PPL:  55.478\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 35/50 [02:18<00:58,  3.93s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.876 | Train PPL:   6.530\n\tValid Loss:   4.083 | Valid PPL:  59.299\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 36/50 [02:22<00:54,  3.90s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.819 | Train PPL:   6.163\n\tValid Loss:   4.045 | Valid PPL:  57.131\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 37/50 [02:26<00:50,  3.88s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.736 | Train PPL:   5.676\n\tValid Loss:   4.013 | Valid PPL:  55.311\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 38/50 [02:30<00:46,  3.88s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.649 | Train PPL:   5.199\n\tValid Loss:   4.014 | Valid PPL:  55.382\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 39/50 [02:34<00:42,  3.85s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.585 | Train PPL:   4.879\n\tValid Loss:   4.017 | Valid PPL:  55.508\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 40/50 [02:37<00:38,  3.85s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.543 | Train PPL:   4.680\n\tValid Loss:   4.089 | Valid PPL:  59.680\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 41/50 [02:41<00:34,  3.85s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.465 | Train PPL:   4.329\n\tValid Loss:   4.051 | Valid PPL:  57.474\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 42/50 [02:45<00:30,  3.86s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.396 | Train PPL:   4.040\n\tValid Loss:   4.088 | Valid PPL:  59.645\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 43/50 [02:49<00:27,  3.86s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.368 | Train PPL:   3.928\n\tValid Loss:   4.096 | Valid PPL:  60.082\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 44/50 [02:53<00:23,  3.85s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.257 | Train PPL:   3.514\n\tValid Loss:   4.095 | Valid PPL:  60.065\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 45/50 [02:57<00:19,  3.87s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.216 | Train PPL:   3.372\n\tValid Loss:   4.072 | Valid PPL:  58.678\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 46/50 [03:01<00:15,  3.89s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.166 | Train PPL:   3.211\n\tValid Loss:   4.110 | Valid PPL:  60.934\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 47/50 [03:05<00:11,  3.89s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.087 | Train PPL:   2.964\n\tValid Loss:   4.169 | Valid PPL:  64.667\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 48/50 [03:09<00:07,  3.89s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   1.042 | Train PPL:   2.835\n\tValid Loss:   4.165 | Valid PPL:  64.390\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 49/50 [03:12<00:03,  3.88s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.987 | Train PPL:   2.684\n\tValid Loss:   4.201 | Valid PPL:  66.780\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [03:16<00:00,  3.93s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   0.928 | Train PPL:   2.529\n\tValid Loss:   4.201 | Valid PPL:  66.756\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"tut1-model.pt\"))\n\ntest_loss = evaluate_fn(model, test_data_loader, criterion, device)\n\nprint(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:50:58.386376Z","iopub.execute_input":"2024-05-28T06:50:58.386817Z","iopub.status.idle":"2024-05-28T06:50:58.593153Z","shell.execute_reply.started":"2024-05-28T06:50:58.386779Z","shell.execute_reply":"2024-05-28T06:50:58.592028Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"| Test Loss: 4.013 | Test PPL:  55.329 |\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate_sentence(\n    sentence,\n    model,\n    de_nlp,\n    en_nlp,\n    de_vocab,\n    en_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n    max_output_length=25,\n):\n    model.eval()\n    with torch.no_grad():\n        if isinstance(sentence, str):\n            tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n        else:\n            tokens = [token for token in sentence]\n        if lower:\n            tokens = [token.lower() for token in tokens]\n        tokens = [sos_token] + tokens + [eos_token]\n        ids = de_vocab.lookup_indices(tokens)\n        tensor = torch.LongTensor(ids).unsqueeze(0).to(device)\n        hidden, cell = model.encoder(tensor)\n        inputs = en_vocab.lookup_indices([sos_token])\n        for _ in range(max_output_length):\n            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n            predicted_token = output.argmax(-1).item()\n            inputs.append(predicted_token)\n            if predicted_token == en_vocab[eos_token]:\n                break\n        tokens = en_vocab.lookup_tokens(inputs)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:50:58.594428Z","iopub.execute_input":"2024-05-28T06:50:58.594837Z","iopub.status.idle":"2024-05-28T06:50:58.605221Z","shell.execute_reply.started":"2024-05-28T06:50:58.594809Z","shell.execute_reply":"2024-05-28T06:50:58.604279Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"sentence = \"I don't understand what you say!!\"","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:54:50.568484Z","iopub.execute_input":"2024-05-28T06:54:50.569366Z","iopub.status.idle":"2024-05-28T06:54:50.573313Z","shell.execute_reply.started":"2024-05-28T06:54:50.569333Z","shell.execute_reply":"2024-05-28T06:54:50.572394Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"translation = translate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    vi_nlp,\n    en_vocab,\n    vi_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:54:51.411479Z","iopub.execute_input":"2024-05-28T06:54:51.412090Z","iopub.status.idle":"2024-05-28T06:54:51.424439Z","shell.execute_reply.started":"2024-05-28T06:54:51.412059Z","shell.execute_reply":"2024-05-28T06:54:51.423376Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"translation","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:54:52.083546Z","iopub.execute_input":"2024-05-28T06:54:52.083969Z","iopub.status.idle":"2024-05-28T06:54:52.090844Z","shell.execute_reply.started":"2024-05-28T06:54:52.083930Z","shell.execute_reply":"2024-05-28T06:54:52.089822Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"['<sos>', 'tôi', 'không', 'biết', 'là', 'bạn', 'có', '.', '.', '<eos>']"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(20):\n    sentence = test_data[i][\"en\"]\n    expected_translation = test_data[i][\"vi\"]\n    translation = translate_sentence(\n    sentence,\n    model,\n    en_nlp,\n    vi_nlp,\n    en_vocab,\n    vi_vocab,\n    lower,\n    sos_token,\n    eos_token,\n    device,\n    )\n    print('----')\n    print(f'Input: {sentence}')\n    print(f'True: {expected_translation}')\n    print(f'Pred: {translation}')","metadata":{"execution":{"iopub.status.busy":"2024-05-28T06:52:26.619262Z","iopub.execute_input":"2024-05-28T06:52:26.619852Z","iopub.status.idle":"2024-05-28T06:52:26.731140Z","shell.execute_reply.started":"2024-05-28T06:52:26.619818Z","shell.execute_reply":"2024-05-28T06:52:26.730223Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"----\nInput: I wish Tom wouldn't sing so loudly late at night.\nTrue: Tôi mong sao Tom đừng hát quá to lúc đêm khuya.\nPred: ['<sos>', 'tôi', 'nghĩ', 'là', 'tom', 'sẽ', 'không', 'đi', 'đến', 'úc', 'vào', 'tuần', '.', '<eos>']\n----\nInput: I went for a walk to get some air.\nTrue: Tôi đã đi dạo để có chút không khí.\nPred: ['<sos>', 'tôi', 'thường', 'ngủ', 'ngủ', 'vào', 'khoảng', 'phút', 'phút', '.', '<eos>']\n----\nInput: Her book is very interesting.\nTrue: Cuốn sách của cô ấy rất thú vị.\nPred: ['<sos>', 'cô', 'ấy', 'đang', 'nấu', 'rất', 'nhiều', '.', '<eos>']\n----\nInput: Tom doesn't eat enough fruit.\nTrue: Tom không ăn đủ trái cây.\nPred: ['<sos>', 'tom', 'không', 'có', 'vẻ', '.', '.', '<eos>']\n----\nInput: If I'd known Tom was in Boston, I'd have told you.\nTrue: Lúc đó nếu tôi biết là Tom ở Boston thì tôi đã nói cho bạn biết rồi.\nPred: ['<sos>', 'nếu', 'tôi', 'biết', 'tom', 'tom', 'đi', 'đi', ',', ',', 'anh', 'ấy', 'đã', 'không', '.', '<eos>']\n----\nInput: We will vote to decide the winner.\nTrue: Chúng ta hãy bỏ phiếu để quyết định người thắng cuộc.\nPred: ['<sos>', 'chúng tôi', 'phải', 'ngồi', 'ở', 'trong', '<unk>', '.', '<eos>']\n----\nInput: Moderate exercise stimulates the circulation of blood.\nTrue: Việc tập thể dục điều độ giúp làm kích thích tuần hoàn máu.\nPred: ['<sos>', '<unk>', '<unk>', '<unk>', 'một', '<unk>', '<unk>', '.', '<eos>']\n----\nInput: I want you to get a good night's rest.\nTrue: Mình mong cậu có một đêm ngủ ngon.\nPred: ['<sos>', 'tôi', 'muốn', 'muốn', 'xem', 'em', '.', '.', '<eos>']\n----\nInput: Are you okay?\nTrue: Bạn có sao không?\nPred: ['<sos>', 'mày', 'có', 'sao', '?', '<eos>']\n----\nInput: Don't you feel hungry?\nTrue: Bạn không cảm thấy đói sao?\nPred: ['<sos>', 'mày', 'mày', 'không', '?', '<eos>']\n----\nInput: Are you a teacher or a student?\nTrue: Bạn là giáo viên hay là học sinh?\nPred: ['<sos>', 'bạn', 'có', 'một', 'người', 'trắng', 'trắng', '.', '<eos>']\n----\nInput: It is very hot today.\nTrue: Hôm nay rất nóng.\nPred: ['<sos>', 'trời', 'rất', 'nóng', '.', '<eos>']\n----\nInput: We'll finish the work even if it takes us all day.\nTrue: Chúng tôi sẽ hoàn thành công việc ngay cả nếu chúng tôi mất cả ngày.\nPred: ['<sos>', 'chúng ta', 'sẽ', 'đi', 'học', 'để', 'bạn', 'chúng ta', 'cần', 'phải', 'đi', 'nó', '.', '<eos>']\n----\nInput: I was the first one to do that.\nTrue: Người đầu tiên làm điều đó là tôi đấy.\nPred: ['<sos>', 'tôi', 'là', 'người', 'người', 'đã', 'làm', 'điều', 'đó', '.', '<eos>']\n----\nInput: This is a portrait of my late father.\nTrue: Đây là bức chân dung người cha đã mất của tôi.\nPred: ['<sos>', 'đây', 'là', 'một', 'sách', 'trong', 'nhất', 'tôi', 'tôi', '.', '<eos>']\n----\nInput: I wasn't allowed to eat anything.\nTrue: Tôi đã không được phép ăn gì cả.\nPred: ['<sos>', 'tôi', 'không', 'có', 'ý định', 'để', 'nói', 'gì', 'cả', '.', '<eos>']\n----\nInput: The school is two kilometers ahead.\nTrue: Ngôi trường ở phía trước 2 cây số.\nPred: ['<sos>', '<unk>', '<unk>', '<unk>', 'vào', '10', '.', '.', '<eos>']\n----\nInput: Even though he apologized, I'm still furious.\nTrue: mặc dù anh ấy đã xin lỗi, tôi vẫn tức giận\nPred: ['<sos>', 'mặc dù', 'người', 'đều', 'đều', 'đi', ',', 'nhưng', 'tôi', 'vẫn', 'sẽ', 'đi', '.', '<eos>']\n----\nInput: I'd help if I could.\nTrue: Em sẽ giúp nếu có thể.\nPred: ['<sos>', 'tôi', 'không thể', 'nói', 'về', 'bài tập', '.', '<eos>']\n----\nInput: He left for London the day before yesterday.\nTrue: Anh ấy đã rời khỏi London vào ngày hôm kia.\nPred: ['<sos>', 'anh', 'ấy', 'đã', 'đi', 'paris', 'vào', 'năm', 'sau', '.', '<eos>']\n","output_type":"stream"}]}]}